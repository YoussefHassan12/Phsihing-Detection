{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36c0663e",
   "metadata": {},
   "source": [
    "<h1 style=\"color:blue; font-size:50px; font-family:Arial\">Features Extraction</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e14aebb",
   "metadata": {},
   "source": [
    "# Pourquoi?\n",
    "\n",
    "L'extraction des caractéristiques des URL est importante pour un modèle de classification de phishing car elle permet de créer des signatures uniques pour les sites malveillants qui peuvent être utilisées pour détecter automatiquement les tentatives de phishing. Les caractéristiques couramment utilisées pour l'analyse de phishing incluent des éléments tels que le nom de domaine, les sous-domaines, les paramètres de l'URL, les numéros de port, les protocoles et les caractères spéciaux. En utilisant ces caractéristiques pour créer des signatures uniques, un modèle de classification peut être formé pour détecter automatiquement les sites malveillants et les ajouter à une liste noire. Cela permet de protéger les utilisateurs contre les tentatives de phishing en temps réel.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3369290",
   "metadata": {},
   "source": [
    "# Les données:\n",
    "\n",
    "Un modèle de classification nécessite des données volumineuses pour deux raisons principales :\n",
    "\n",
    "La complexité des données : Les modèles de classification sont utilisés pour reconnaître des patterns ou des tendances dans les données. Plus les données sont variées et complexes, plus il est difficile pour un modèle de les comprendre et de les classer correctement. Avoir un grand volume de données permet de capturer cette complexité et de mieux entraîner le modèle.\n",
    "\n",
    "La précision du modèle : Plus le modèle est entraîné sur un grand volume de données, plus il est capable de généraliser correctement aux nouvelles données. Cela signifie qu'il est moins susceptible de commettre des erreurs lors de la classification de nouveaux exemples. Les données volumineuses permettent également de réduire la variance et l'erreur générale du modèle, augmentant ainsi la précision de la classification.\n",
    "\n",
    "En somme, disposer d'un grand volume de données permet d'entraîner un modèle plus complexe et plus précis. Il est donc important de disposer d'un grand jeu de données pour entraîner efficacement un modèle de classification.\n",
    "\n",
    "En revanche, par manque de ressources, et vu que l'objectif du présent projet est avant tout de présenter l'approche suivie pour identifier les attaques phishing, on a décidé de nous limiter à des data sets non volumineuses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c03ebf8",
   "metadata": {},
   "source": [
    "# <u> Phishing URLs Data source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52e7075",
   "metadata": {},
   "source": [
    "Il n'y a pas de services gratuits d'API de phishing URL car la détection de phishing est un travail complexe qui nécessite des ressources importantes pour maintenir et mettre à jour régulièrement les bases de données de sites malveillants. Les entreprises qui offrent des services de détection de phishing facturent généralement leurs clients pour couvrir les coûts liés à ces activités de maintenance et de mise à jour. De plus, les API de phishing ont souvent des exigences de confidentialité et de sécurité élevées qui doivent être respectées pour protéger les données des utilisateurs. \n",
    "\n",
    "Pour Ce projet, on avait deux solutions: Utiliser une base des données csv gratuite, mais  l'utilisation d'une telle base de données gratuite pourra ne pas être aussi efficace que des services payants qui ont des moyens pour mettre à jour régulièrement les données et les entretenir. Alors on a decidé de recourir au site Openphish. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50223a03",
   "metadata": {},
   "source": [
    "## OpenPhish\n",
    "\n",
    "OpenPhish est un service de détection de phishing automatisé qui utilise des techniques d'analyse de données et d'apprentissage automatique pour détecter les sites de phishing. Il utilise des données en temps réel pour identifier les sites malveillants et les ajouter à sa liste noire. Les utilisateurs peuvent accéder à cette liste noire via une API pour vérifier les URL et protéger leur entreprise contre les tentatives de phishing. OpenPhish est un service payant qui est utilisé par les entreprises pour protéger leurs employés et leurs données contre les menaces de phishing en ligne.\n",
    "\n",
    "Vu nos ressources limitées, on s'est contenté de réaliser un simple web scrapping depuis la page d'accueil d'OpenPhish où les 500 derniers URLs considérés comme phising sont listés. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e861110c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ipaddress\n",
    "import re\n",
    "from urllib.parse import urlparse\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86b685c8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.solutionfun.info/landingpage/dd2638...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://36560022.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.panicasa.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://5467wa.ihostfull.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://nodesdatas.online</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>https://welltododearl.polarcita36.repl.co</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>http://binaryresistor.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>https://oidc.idp.elogin.e-access-itservices.co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>http://dontforgettoeat-foodforthought.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>http://bafybeigweboapad7566l75baj7vjyzg2pdcia7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   URL\n",
       "0    http://www.solutionfun.info/landingpage/dd2638...\n",
       "1                                  http://36560022.com\n",
       "2                              http://www.panicasa.com\n",
       "3                          http://5467wa.ihostfull.com\n",
       "4                             http://nodesdatas.online\n",
       "..                                                 ...\n",
       "495          https://welltododearl.polarcita36.repl.co\n",
       "496                          http://binaryresistor.com\n",
       "497  https://oidc.idp.elogin.e-access-itservices.co...\n",
       "498          http://dontforgettoeat-foodforthought.com\n",
       "499  http://bafybeigweboapad7566l75baj7vjyzg2pdcia7...\n",
       "\n",
       "[500 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://openphish.com/feed.txt\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "phishing_df= pd.DataFrame({\"URL\":str(soup).split()})\n",
    "\n",
    "phishing_df=pd.DataFrame(phishing_df[\"URL\"].apply(lambda x:x.rstrip(x[-1])))\n",
    "\n",
    "phishing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cd82dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a;lamlm'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=\"a;lamlm/\"\n",
    "a.rstrip(a[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa1797e",
   "metadata": {},
   "source": [
    "# <u> Legitimate URLs Data source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790fa221",
   "metadata": {},
   "source": [
    "# Moz Top 500\n",
    "\n",
    "Moz Top 500 est une liste des sites les plus populaires sur Internet, classés par leur autorité de domaine (DA) de Moz. Le DA est un score de 1 à 100 qui mesure la qualité et la quantité des liens pointant vers un site. Plus le DA d'un site est élevé, plus il est considéré comme fiable et de qualité par les moteurs de recherche. La liste Moz Top 500 est mise à jour régulièrement et est basée sur les données de l'outil de référencement de Moz, Open Site Explorer. \n",
    "\n",
    "Cette liste est utilisée pour fournir des URLs légitimes pour ce projet de classification de phishing URLs. En utilisant des URLs de sites de haute qualité et de confiance, classés par leur autorité de domaine, on peut entraîner un modèle de classification pour reconnaître les URLs légitimes et les distinguer des URLs de phishing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35d013db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.blogger.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.google.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://youtube.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://linkedin.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://support.google.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>https://merriam-webster.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>https://public-api.wordpress.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>https://techradar.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>https://greenpeace.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>https://corriere.it</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  URL\n",
       "0             https://www.blogger.com\n",
       "1              https://www.google.com\n",
       "2                 https://youtube.com\n",
       "3                https://linkedin.com\n",
       "4          https://support.google.com\n",
       "..                                ...\n",
       "495       https://merriam-webster.com\n",
       "496  https://public-api.wordpress.com\n",
       "497             https://techradar.com\n",
       "498            https://greenpeace.org\n",
       "499               https://corriere.it\n",
       "\n",
       "[500 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leg_df=pd.read_csv(\"top500Domains.csv\",usecols=[\"Root Domain\"])\n",
    "leg_df.columns=[\"URL\"]\n",
    "leg_df[\"URL\"]=\"https://\"+leg_df[\"URL\"] #juste pour la propre execution de feature 8\n",
    "leg_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdeefcd",
   "metadata": {},
   "source": [
    "### Featue 1: Le nom du domaine de l' URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64bad86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tldextract\n",
    "def extract_domain_name(url):\n",
    "    extracted = tldextract.extract(url)\n",
    "    return extracted.domain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1db25f7",
   "metadata": {},
   "source": [
    "### Featue 2: La présence du IP adress  dans le URL\n",
    "\n",
    "On vérifie la présence de l'adresse IP dans l'URL. Les URLs peuvent avoir une adresse IP au lieu d'un nom de domaine. Si c'est le cas, nous pouvons être sûrs que quelqu'un essaie de voler des informations personnelles avec cette URL.\n",
    "\n",
    "Si la partie domaine de l'URL contient une adresse IP, la valeur attribuée à Ce feature est 1 (Phishing) et 0 (legitimate) si non."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b1352da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ip_ds_URL(url):\n",
    "    try:\n",
    "        ip_address = re.search(r'[0-9]+(?:\\.[0-9]+){3}', url).group()\n",
    "        ip = 1\n",
    "    except:\n",
    "        ip = 0\n",
    "    return ip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898041f0",
   "metadata": {},
   "source": [
    "### Featue 3 : La présence du \"@\"  dans le URL\n",
    "\n",
    "L'utilisation du symbole \"@\" dans l'URL conduit le navigateur à ignorer tout ce qui précède le symbole \"@\". Ainsi, de nombreux attaquants l'utilisent pour tromper les utilisateurs.\n",
    "\n",
    "Si l'URL contient le symbole '@', la valeur attribuée à Ce feature est 1 (Phishing) et 0 (legitimate) si non."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b908278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def at_ds_URL(url):\n",
    "    if \"@\" in url:\n",
    "        at = 1    \n",
    "    else:\n",
    "        at = 0    \n",
    "    return at"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28f54df",
   "metadata": {},
   "source": [
    "### Feature 4: longueur de l' URL\n",
    "\n",
    "D'abord on calcule les moyennes des longueurs des phishing URLs et des Legitimate URLs.\n",
    "\n",
    "Si la longueur de l'URL est plus proche à la moyenne des phishing URLs, la valeur attribuée à Ce feature est 1 (Phishing) et 0 (legitimate) si non."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6705847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# la moyenne des longueurs des phishing URLs.\n",
    "m_phish= int(np.array(phishing_df['URL'].apply(lambda x: len(x))).mean())\n",
    "# la moyenne des longueurs des Legitimate URLs\n",
    "m_leg= int(np.array(leg_df['URL'].apply(lambda x: len(x))).mean())\n",
    "\n",
    "def long_URL(url):\n",
    "    if (abs(len(url)-m_phish) > abs(len(url)-m_leg)):\n",
    "        return 0            \n",
    "    else:\n",
    "        return 1            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc84fd8",
   "metadata": {},
   "source": [
    "### Feature 5: Profondeur de l' URL\n",
    "\n",
    "La profondeur d'un site correspond au nombre de clics entre une page donnée et la page d'accueil.\n",
    "\n",
    "Ce feature calcule le nombre de sous-pages dans l'URL donnée en fonction du '/'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52955e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prof_URL(url):\n",
    "    s = urlparse(url).path.split('/')\n",
    "    depth = 0\n",
    "    for j in range(len(s)):\n",
    "        if len(s[j]) != 0:\n",
    "            depth = depth+1\n",
    "    return depth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b481f7f1",
   "metadata": {},
   "source": [
    "### Feature 6: Nombre de caractères spéciaux dans l' URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26cdd131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_of_special_caract(url):\n",
    "    special_characters = re.findall(r\"[^a-zA-Z0-9./]\", url)\n",
    "    return len(special_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c28f166",
   "metadata": {},
   "source": [
    "### Feature 7:  Redirection \"//\" dans l' URL\n",
    "\n",
    "On vérifie la présence de \"//\" dans l'URL. L'existence de \"//\" dans le domaine de l'URL signifie que l'utilisateur sera redirigé vers un autre site Web.\n",
    "\n",
    "Si le \"//\" est n'importe où dans l'URL ( sauf apres http ou https) , la valeur attribuée à ce feature est 1 (phishing) et 0 (legitimate) si non."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e607982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def redirection(url):\n",
    "    pos = url.rfind('//')\n",
    "    if pos >= 7:  # après http:// (7 caractère)\n",
    "        if pos >= 8: # après https:// (8 caractère)\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364bfa34",
   "metadata": {},
   "source": [
    "### Feature 8: La présence du \"http\" ou \"https\" dans le domaine de l' URL\n",
    "\n",
    "On vérifie la présence de \"http/https\" dans la partie domaine de l'URL. Les phishers peuvent les ajouter à la partie domaine d'une URL afin de tromper les utilisateurs.\n",
    "\n",
    "Si l'URL contient \"http/https\" dans son domaine, la valeur attribuée à ce feature est 1 (phishing) et 0 (legitimate) si non."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e83a31fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def http_ds_domaine(url):\n",
    "    domain = urlparse(url).netloc\n",
    "    if ('http' or 'https') in domain:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ce44ad",
   "metadata": {},
   "source": [
    "### Feature 9: L'utilisation des réducteurs d'URL \n",
    "\n",
    "Un réducteur d'URL est un outil qui permet de raccourcir un lien. De nombreux outils en ligne proposent aux utilisateurs de réduire automatiquement leurs liens trop longs et sont largement utilisé dans les phsihing attaques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75f2fe11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# les services les plus utiliser\n",
    "red_serv = r\"bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|\" \\\n",
    "                      r\"yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|\" \\\n",
    "                      r\"short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|\" \\\n",
    "                      r\"doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|db\\.tt|\" \\\n",
    "                      r\"qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|q\\.gs|is\\.gd|\" \\\n",
    "                      r\"po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|x\\.co|\" \\\n",
    "                      r\"prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|\" \\\n",
    "                      r\"tr\\.im|link\\.zip\\.net\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e04c655",
   "metadata": {},
   "outputs": [],
   "source": [
    "def red_URL(url):\n",
    "    match=re.search(red_serv,url)\n",
    "    if match:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f256cd9a",
   "metadata": {},
   "source": [
    "### Le service Whois\n",
    "\n",
    "Whois est un service de recherche fourni par les registres Internet permettant d'obtenir des informations sur une adresse IP ou un nom de domaine. \n",
    "\n",
    "On va utiliser cette base des données afin d'extraire des features addtionnelles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f43ee7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install python-whois\n",
    "import whois"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2dc41e",
   "metadata": {},
   "source": [
    "### Feature 10: Si l'URL existe dans la base des données whois\n",
    "\n",
    "c'est implémenté automatiquement dans la fonction des Feature_extraction.\n",
    "\n",
    "si il n'existe pas,  la valeur attribuée à ce feature est 1 (phishing) et 0 (legitimate) si non.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e787d397",
   "metadata": {},
   "source": [
    "### Feature 11:Période de validité du domaine\n",
    "\n",
    "Ce Feature est calculé en utilisant la base de données WHOIS. La plupart des sites Web de phishing ont une courte période de validité. On va calculer la période moyenne des phishing urls, de même pour des legitimate urls.\n",
    "\n",
    "Si la Période de validité de l'URL est plus proche de la moyenne des phishing urls, la valeur attribuée à ce feature est 1 (phishing) et 0 (legitimate) si non."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8c0530",
   "metadata": {},
   "source": [
    "##### On commence en calculant  la période de validité moyenne des phishing urls. \n",
    "<b>NB:</b> La time complexity de ce calcul est élévée. Dès lors, on se contente de le réaliser une seule fois. Au cas où on décide de changer les données, on prend une valeur approximative de celle qu'on a déjà trouvé sans avoir à refaire le calcul."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aac074ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [WinError 10061] No connection could be made because the target machine actively refused it\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1890.5974842767296"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#phish_sample=phishing_df.sample(500).reset_index(drop=True)\n",
    "pv_of_phsishing_urls=[]\n",
    "\n",
    "for i in range (len(phishing_df)):\n",
    "    url=phishing_df['URL'][i]\n",
    "    try:\n",
    "        domain_name=whois.whois(urlparse(url).netloc)\n",
    "        creation_date = domain_name.creation_date\n",
    "        expiration_date = domain_name.expiration_date\n",
    "        if (isinstance(creation_date,str) or isinstance(expiration_date,str)):\n",
    "            try:\n",
    "                creation_date = datetime.strptime(creation_date,'%Y-%m-%d')\n",
    "                expiration_date = datetime.strptime(expiration_date,\"%Y-%m-%d\")\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "        elif ((type(expiration_date) is list) and (type(creation_date) is list)):\n",
    "            creation_date = creation_date[0]\n",
    "            expiration_date = expiration_date[0] \n",
    "            \n",
    "        elif (type(expiration_date) is list):\n",
    "                expiration_date = expiration_date[0]\n",
    "                \n",
    "        elif (type(creation_date) is list):\n",
    "                creation_date = creation_date[0]        \n",
    "        \n",
    "        pv_of_phsishing_urls.append((expiration_date-creation_date).days)\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "mean_pv_phish=sum(pv_of_phsishing_urls)/len(pv_of_phsishing_urls) \n",
    "mean_pv_phish"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a06fde",
   "metadata": {},
   "source": [
    "##### puis on calcule la période de validité moyenne des legitimate urls\n",
    "<b>NB:</b> La time complexity de ce calcul est élévée. Dès lors, on se contente de le réaliser une seule fois. Au cas où on décide de changer les données, on prend une valeur approximative de celle qu'on a déjà trouvé sans avoir à refaire le calcul."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1084e81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8960.993119266055"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#leg_sample=leg_df.sample(500).reset_index(drop=True)\n",
    "pv_of_leg_urls=[]\n",
    "for i in range (len(leg_df)):\n",
    "    url = leg_df['URL'][i]\n",
    "    try:\n",
    "        domain_name=whois.whois(urlparse(url).netloc)\n",
    "        creation_date = domain_name.creation_date\n",
    "        expiration_date = domain_name.expiration_date\n",
    "        if (isinstance(creation_date,str) or isinstance(expiration_date,str)):\n",
    "            try:\n",
    "                creation_date = datetime.strptime(creation_date,'%Y-%m-%d')\n",
    "                expiration_date = datetime.strptime(expiration_date,\"%Y-%m-%d\")\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "        elif ((type(expiration_date) is list) and (type(creation_date) is list)):\n",
    "            creation_date = creation_date[0]\n",
    "            expiration_date = expiration_date[0] \n",
    "            \n",
    "        elif (type(expiration_date) is list):\n",
    "                expiration_date = expiration_date[0]\n",
    "                \n",
    "        elif (type(creation_date) is list):\n",
    "                creation_date = creation_date[0]\n",
    "                \n",
    "        pv_of_leg_urls.append((expiration_date-creation_date).days)\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "mean_pv_leg=sum(pv_of_leg_urls)/len(pv_of_leg_urls) \n",
    "mean_pv_leg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17639a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def periode_vie_url(domain_name):\n",
    "    try:\n",
    "        creation_date = domain_name.creation_date\n",
    "        expiration_date = domain_name.expiration_date\n",
    "        \n",
    "        if (isinstance(creation_date,str) or isinstance(expiration_date,str)):\n",
    "            try:\n",
    "                creation_date = datetime.strptime(creation_date,'%Y-%m-%d')\n",
    "                expiration_date = datetime.strptime(expiration_date,\"%Y-%m-%d\")\n",
    "            except:\n",
    "                return 1\n",
    "                \n",
    "        elif ((type(expiration_date) is list) and (type(creation_date) is list)):\n",
    "            creation_date = creation_date[0]\n",
    "            expiration_date = expiration_date[0] \n",
    "            \n",
    "        elif (type(expiration_date) is list):\n",
    "                expiration_date = expiration_date[0]\n",
    "                \n",
    "        elif (type(creation_date) is list):\n",
    "                creation_date = creation_date[0]\n",
    "        \n",
    "        \n",
    "        pvofdomain=(expiration_date-creation_date).days\n",
    "        \n",
    "        if abs(pvofdomain-mean_pv_phish)<abs(pvofdomain-mean_pv_leg):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    except:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363dcd27",
   "metadata": {},
   "source": [
    "### Feature 12:l'âge du domaine\n",
    "\n",
    "Ce Feature est calculé en utilisant la base de données WHOIS. La plupart des sites Web de phishing vivent pendant une courte période. On va calculer l'âge moyen des phishing urls, de même pour des legitimate urls.\n",
    "\n",
    "Si l'âge du domaine est plus proche de l'âge moyen des phishing urls, la valeur attribuée à ce feature est 1 (phishing) et 0 (legitimate) si non."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f591888f",
   "metadata": {},
   "source": [
    "###### On calcule de l'âge moyen d'un échantillon des phishing urls\n",
    "<b>NB:</b> La time complexity de ce calcul est élévée. Dès lors, on se contente de le réaliser une seule fois. Au cas où on décide de changer les données, on prend une valeur approximative de celle qu'on a déjà trouvé sans avoir à refaire le calcul."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "389b74b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [WinError 10061] No connection could be made because the target machine actively refused it\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1523.191222570533"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#phish_sample=phishing_df.sample(500).reset_index(drop=True)\n",
    "age_of_phsishing_urls=[]\n",
    "\n",
    "for i in range (len(phishing_df)):\n",
    "    url=phishing_df['URL'][i]\n",
    "    try:\n",
    "        domain_name=whois.whois(urlparse(url).netloc)\n",
    "        creation_date = domain_name.creation_date\n",
    "        if isinstance(creation_date,str):\n",
    "            try:\n",
    "                creation_date = datetime.strptime(creation_date,'%Y-%m-%d')\n",
    "            except:\n",
    "                continue\n",
    "        elif (type(creation_date) is list):\n",
    "                creation_date = creation_date[0]        \n",
    "        \n",
    "        age_of_phsishing_urls.append((datetime.now()-creation_date).days)\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "mean_age_phish=sum(age_of_phsishing_urls)/len(age_of_phsishing_urls) \n",
    "mean_age_phish"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4690a2f",
   "metadata": {},
   "source": [
    "###### On calcule de l'âge moyen d'un échantillon des legitimate urls\n",
    "<b>NB:</b> La time complexity de ce calcul est élévée. Dès lors, on se contente de le réaliser une seule fois. Au cas où on décide de changer les données, on prend une valeur approximative de celle qu'on a déjà trouvé sans avoir à refaire le calcul."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5324a944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8214.798185941043"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#leg_sample=leg_df.sample(500).reset_index(drop=True)\n",
    "age_of_leg_urls=[]\n",
    "for i in range (len(leg_df)):\n",
    "    url = leg_df['URL'][i]\n",
    "    try:\n",
    "        domain_name=whois.whois(urlparse(url).netloc)\n",
    "        creation_date = domain_name.creation_date\n",
    "        if isinstance(creation_date,str):\n",
    "            try:\n",
    "                creation_date = datetime.strptime(creation_date,'%Y-%m-%d')\n",
    "            except:\n",
    "                continue\n",
    "        elif (type(creation_date) is list):\n",
    "                creation_date = creation_date[0]        \n",
    "        \n",
    "        age_of_leg_urls.append((datetime.now()-creation_date).days)\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "mean_age_leg=sum(age_of_leg_urls)/len(age_of_leg_urls) \n",
    "mean_age_leg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb0fd042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_url(domain_name):\n",
    "    try:\n",
    "        creation_date = domain_name.creation_date\n",
    "        expiration_date = domain_name.expiration_date\n",
    "        if isinstance(creation_date,str):\n",
    "            try:\n",
    "                creation_date = datetime.strptime(creation_date,'%Y-%m-%d')\n",
    "            except:\n",
    "                return 1\n",
    "        elif (type(creation_date) is list):\n",
    "                creation_date = creation_date[0]\n",
    "                \n",
    "        ageofdomain=(datetime.now()-creation_date).days\n",
    "        \n",
    "        if abs(ageofdomain-mean_age_phish)<abs(ageofdomain-mean_age_leg):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacf865c",
   "metadata": {},
   "source": [
    "### Feature 13: IFrame Redirection\n",
    "\n",
    "Les phishers utilisent les iframes HTML pour intégrer des pages web malveillantes dans des pages web légitimes dans le but de voler des informations personnelles ou financières des utilisateurs. Les iframes permettent aux attaquants de masquer les pages malveillantes en les intégrant dans des pages web légitimes, ce qui rend plus difficile pour les utilisateurs de détecter les tentatives de phishing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23c9f2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iframe(response):\n",
    "    if response == \"\":\n",
    "        return 1\n",
    "    else:\n",
    "        if re.findall(r\"[<iframe>|<frameBorder>]\", response.text):\n",
    "            return 0\n",
    "        else:\n",
    "            return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed51e579",
   "metadata": {},
   "source": [
    "### Feature 14: Website Forwarding\n",
    "\n",
    "Le Website Forwarding, également appelé redirection de site web, est une fonctionnalité qui permet de rediriger automatiquement les utilisateurs d'un site web vers une autre URL lorsqu'ils accèdent au site d'origine.\n",
    "\n",
    "Les phishers utilisent souvent le Website Forwarding pour rediriger les utilisateurs vers des sites web de phishing qui ressemblent à des sites web légitimes.\n",
    "\n",
    "Ce feature va juste compter les redictions de l'URL.\n",
    "\n",
    "<b> NB: </b> la différence entre ce feature est le feature 7 est que le forwarding de site web est une fonctionnalité qui permet de rediriger les utilisateurs vers une autre URL alors que \"//\" est une syntaxe utilisée dans les URLs pour spécifier un protocole relatif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b509008a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwarding(response):\n",
    "    if response == \"\":\n",
    "        return 1\n",
    "    else:\n",
    "        return len(response.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4cabceaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to extract features\n",
    "def featureExtraction(url,label):\n",
    "\n",
    "    features = []\n",
    "    features.append(extract_domain_name(url))\n",
    "    features.append(ip_ds_URL(url))\n",
    "    features.append(at_ds_URL(url))\n",
    "    features.append(long_URL(url))\n",
    "    features.append(prof_URL(url))\n",
    "    features.append(nb_of_special_caract(url))\n",
    "    features.append(redirection(url))\n",
    "    features.append(http_ds_domaine(url))\n",
    "    features.append(red_URL(url))\n",
    "    \n",
    "    wis = 0\n",
    "    try:\n",
    "        domain_name = whois.whois(urlparse(url).netloc)\n",
    "    except:\n",
    "        wis = 1\n",
    "        \n",
    "    features.append(wis)\n",
    "    features.append(1 if wis == 1 else periode_vie_url(domain_name))\n",
    "    features.append(1 if wis == 1 else age_url(domain_name))\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url,timeout=20)\n",
    "    except:\n",
    "        response = \"\"\n",
    "    \n",
    "    features.append(iframe(response))\n",
    "    features.append(forwarding(response))\n",
    "    \n",
    "    features.append(label)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c59b41b",
   "metadata": {},
   "source": [
    "# L'extraction des features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c16f86",
   "metadata": {},
   "source": [
    "## 1. Phishing URLs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aac6c47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "Error trying to connect to socket: closing socket - [WinError 10061] No connection could be made because the target machine actively refused it\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n",
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n"
     ]
    }
   ],
   "source": [
    "phish_features = []\n",
    "label = 1\n",
    "\n",
    "for i in range(0, 500):\n",
    "    \n",
    "    url = phishing_df['URL'][i]\n",
    "    phish_features.append(featureExtraction(url,label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "751e91f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nom_de_Domaine</th>\n",
       "      <th>have_IP</th>\n",
       "      <th>have_at</th>\n",
       "      <th>longueur</th>\n",
       "      <th>profondeur</th>\n",
       "      <th>nb_de_caractere_spec</th>\n",
       "      <th>redirection</th>\n",
       "      <th>http_ds_domaine</th>\n",
       "      <th>red_URL</th>\n",
       "      <th>whois</th>\n",
       "      <th>periode_de_vie</th>\n",
       "      <th>age_url</th>\n",
       "      <th>iframe</th>\n",
       "      <th>forwarding</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>solutionfun</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36560022</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>panicasa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ihostfull</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nodesdatas</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Nom_de_Domaine  have_IP  have_at  longueur  profondeur  \\\n",
       "0    solutionfun        0        0         1           3   \n",
       "1       36560022        0        0         0           0   \n",
       "2       panicasa        0        0         0           0   \n",
       "3      ihostfull        0        0         0           0   \n",
       "4     nodesdatas        0        0         0           0   \n",
       "\n",
       "   nb_de_caractere_spec  redirection  http_ds_domaine  red_URL  whois  \\\n",
       "0                     6            0                0        0      0   \n",
       "1                     1            0                0        0      0   \n",
       "2                     1            0                0        0      0   \n",
       "3                     1            0                0        0      0   \n",
       "4                     1            0                0        0      0   \n",
       "\n",
       "   periode_de_vie  age_url  iframe  forwarding  label  \n",
       "0               1        1       0           1      1  \n",
       "1               1        1       1           1      1  \n",
       "2               1        1       0           0      1  \n",
       "3               1        1       0           0      1  \n",
       "4               1        1       1           1      1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names=[\"Nom_de_Domaine\",\"have_IP\",\"have_at\",\"longueur\",\"profondeur\",\"nb_de_caractere_spec\",\n",
    "               \"redirection\",\"http_ds_domaine\",\"red_URL\",\"whois\",\"periode_de_vie\",\"age_url\",\"iframe\",\"forwarding\",\"label\"]\n",
    "phishing = pd.DataFrame(phish_features, columns= feature_names)\n",
    "phishing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef97e4d",
   "metadata": {},
   "source": [
    "## 2. legitimate URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0482d497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error trying to connect to socket: closing socket - [Errno 11001] getaddrinfo failed\n"
     ]
    }
   ],
   "source": [
    "legi_features = []\n",
    "label = 0\n",
    "\n",
    "for i in range(500):\n",
    "\n",
    "    url = leg_df['URL'][i]\n",
    "    legi_features.append(featureExtraction(url,label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff7b8596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nom_de_Domaine</th>\n",
       "      <th>have_IP</th>\n",
       "      <th>have_at</th>\n",
       "      <th>longueur</th>\n",
       "      <th>profondeur</th>\n",
       "      <th>nb_de_caractere_spec</th>\n",
       "      <th>redirection</th>\n",
       "      <th>http_ds_domaine</th>\n",
       "      <th>red_URL</th>\n",
       "      <th>whois</th>\n",
       "      <th>periode_de_vie</th>\n",
       "      <th>age_url</th>\n",
       "      <th>iframe</th>\n",
       "      <th>forwarding</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blogger</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>google</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>youtube</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>linkedin</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>google</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Nom_de_Domaine  have_IP  have_at  longueur  profondeur  \\\n",
       "0        blogger        0        0         0           0   \n",
       "1         google        0        0         0           0   \n",
       "2        youtube        0        0         0           0   \n",
       "3       linkedin        0        0         0           0   \n",
       "4         google        0        0         0           0   \n",
       "\n",
       "   nb_de_caractere_spec  redirection  http_ds_domaine  red_URL  whois  \\\n",
       "0                     1            0                0        0      0   \n",
       "1                     1            0                0        0      0   \n",
       "2                     1            0                0        0      0   \n",
       "3                     1            0                0        0      0   \n",
       "4                     1            0                0        0      0   \n",
       "\n",
       "   periode_de_vie  age_url  iframe  forwarding  label  \n",
       "0               0        0       0           4      0  \n",
       "1               0        0       0           0      0  \n",
       "2               0        0       0           1      0  \n",
       "3               0        0       0           1      0  \n",
       "4               0        0       0           0      0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names=[\"Nom_de_Domaine\",\"have_IP\",\"have_at\",\"longueur\",\"profondeur\",\"nb_de_caractere_spec\",\n",
    "               \"redirection\",\"http_ds_domaine\",\"red_URL\",\"whois\",\"periode_de_vie\",\"age_url\",\"iframe\",\"forwarding\",\"label\"]\n",
    "legitimate = pd.DataFrame(legi_features, columns= feature_names)\n",
    "legitimate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db98b4df",
   "metadata": {},
   "source": [
    "#  Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7908987f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nom_de_Domaine</th>\n",
       "      <th>have_IP</th>\n",
       "      <th>have_at</th>\n",
       "      <th>longueur</th>\n",
       "      <th>profondeur</th>\n",
       "      <th>nb_de_caractere_spec</th>\n",
       "      <th>redirection</th>\n",
       "      <th>http_ds_domaine</th>\n",
       "      <th>red_URL</th>\n",
       "      <th>whois</th>\n",
       "      <th>periode_de_vie</th>\n",
       "      <th>age_url</th>\n",
       "      <th>iframe</th>\n",
       "      <th>forwarding</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blogger</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>google</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>youtube</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>linkedin</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>google</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Nom_de_Domaine  have_IP  have_at  longueur  profondeur  \\\n",
       "0        blogger        0        0         0           0   \n",
       "1         google        0        0         0           0   \n",
       "2        youtube        0        0         0           0   \n",
       "3       linkedin        0        0         0           0   \n",
       "4         google        0        0         0           0   \n",
       "\n",
       "   nb_de_caractere_spec  redirection  http_ds_domaine  red_URL  whois  \\\n",
       "0                     1            0                0        0      0   \n",
       "1                     1            0                0        0      0   \n",
       "2                     1            0                0        0      0   \n",
       "3                     1            0                0        0      0   \n",
       "4                     1            0                0        0      0   \n",
       "\n",
       "   periode_de_vie  age_url  iframe  forwarding  label  \n",
       "0               0        0       0           4      0  \n",
       "1               0        0       0           0      0  \n",
       "2               0        0       0           1      0  \n",
       "3               0        0       0           1      0  \n",
       "4               0        0       0           0      0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Concaténer les deux dataframes \n",
    "urldata = pd.concat([legitimate, phishing]).reset_index(drop=True)\n",
    "urldata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f86703b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "urldata.to_csv('urldata.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030f57fb",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "L'objectif de ce notebook est atteint. Nous avons finalement extrait 15 features pour 1000 URL dont 500 URL sont de phishing et 500 URL sont légitimes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5051968a",
   "metadata": {},
   "source": [
    "# Références\n",
    "\n",
    "http://eprints.hud.ac.uk/id/eprint/24330/6/MohammadPhishing14July2015.pdf\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
